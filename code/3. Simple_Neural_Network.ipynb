{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:01.491167Z",
     "start_time": "2019-08-12T11:55:54.073345Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.272671Z",
     "start_time": "2019-08-12T11:56:01.494162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4288697d64d6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/arif/anaconda3/envs/env_kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/arif/anaconda3/envs/env_kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arif/anaconda3/envs/env_kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arif/anaconda3/envs/env_kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arif/anaconda3/envs/env_kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)  # y labels are oh-encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.277781Z",
     "start_time": "2019-08-12T11:56:02.274415Z"
    }
   },
   "outputs": [],
   "source": [
    "n_train = mnist.train.num_examples  # 55,000\n",
    "n_validation = mnist.validation.num_examples  # 5000\n",
    "n_test = mnist.test.num_examples  # 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.452401Z",
     "start_time": "2019-08-12T11:56:02.279541Z"
    }
   },
   "outputs": [],
   "source": [
    "n_input = 784  # input layer (28x28 pixels)\n",
    "# n_hidden1 = 512  # 1st hidden layer\n",
    "# n_hidden2 = 256  # 2nd hidden layer\n",
    "# n_hidden3 = 128  # 3rd hidden layer\n",
    "n_output = 10  # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.560152Z",
     "start_time": "2019-08-12T11:56:02.454451Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.648100Z",
     "start_time": "2019-08-12T11:56:02.562150Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cara 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.738307Z",
     "start_time": "2019-08-12T11:56:02.650966Z"
    }
   },
   "outputs": [],
   "source": [
    "# weights = {\n",
    "#     'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
    "#     'w2': tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "#     'w3': tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "#     'out': tf.Variable(tf.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.818086Z",
     "start_time": "2019-08-12T11:56:02.741445Z"
    }
   },
   "outputs": [],
   "source": [
    "# biases = {\n",
    "#     'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "#     'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "#     'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "#     'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:02.915691Z",
     "start_time": "2019-08-12T11:56:02.820075Z"
    }
   },
   "outputs": [],
   "source": [
    "# layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "# layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "# layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "# layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "# output_layer = tf.matmul(layer_3, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cara 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.061137Z",
     "start_time": "2019-08-12T11:56:02.918548Z"
    }
   },
   "outputs": [],
   "source": [
    "# now declare the weights connecting the input to the hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "# and the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.120059Z",
     "start_time": "2019-08-12T11:56:03.063708Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the output of the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(X, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.220877Z",
     "start_time": "2019-08-12T11:56:03.122875Z"
    }
   },
   "outputs": [],
   "source": [
    "# now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "# output layer\n",
    "output_layer = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.589460Z",
     "start_time": "2019-08-12T11:56:03.223481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-a712c0a48de1>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=Y, logits=output_layer\n",
    "        ))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.606011Z",
     "start_time": "2019-08-12T11:56:03.591446Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:03.752541Z",
     "start_time": "2019-08-12T11:56:03.608993Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:06.833838Z",
     "start_time": "2019-08-12T11:56:03.754685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 2.295102 \t| Accuracy = 0.1640625\n",
      "Iteration 100 \t| Loss = 2.1212955 \t| Accuracy = 0.5390625\n",
      "Iteration 200 \t| Loss = 1.8516973 \t| Accuracy = 0.7265625\n",
      "Iteration 300 \t| Loss = 1.8192923 \t| Accuracy = 0.765625\n",
      "Iteration 400 \t| Loss = 1.8212367 \t| Accuracy = 0.6953125\n",
      "Iteration 500 \t| Loss = 1.7793 \t| Accuracy = 0.71875\n",
      "Iteration 600 \t| Loss = 1.6902881 \t| Accuracy = 0.84375\n",
      "Iteration 700 \t| Loss = 1.7096441 \t| Accuracy = 0.796875\n",
      "Iteration 800 \t| Loss = 1.6687572 \t| Accuracy = 0.828125\n",
      "Iteration 900 \t| Loss = 1.674547 \t| Accuracy = 0.8359375\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        X: batch_x, Y: batch_y, keep_prob: dropout\n",
    "        })\n",
    "\n",
    "    # print loss and accuracy (per minibatch)\n",
    "    if i % 100 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run(\n",
    "            [cross_entropy, accuracy],\n",
    "            feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0}\n",
    "            )\n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t| Loss =\",\n",
    "            str(minibatch_loss),\n",
    "            \"\\t| Accuracy =\",\n",
    "            str(minibatch_accuracy)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:06.886600Z",
     "start_time": "2019-08-12T11:56:06.835544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test set: 0.8288\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0})\n",
    "print(\"\\nAccuracy on test set:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:07.015552Z",
     "start_time": "2019-08-12T11:56:06.888424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAQAAACIlMtcAAAAAmJLR0T//xSrMc0AAAAJcEhZcwAAAEgAAABIAEbJaz4AAAAJdnBBZwAAABwAAAAcAIexIrQAAACTSURBVEjHY/hPZ8AwauGgsLChAYJpaiHMEkdHVEwTC2EWofsMJkZVCz98+P/fwQFC43II1X344AFuOVJ9SXEqJTUBjVpIdoKiuoWwFFpYSIeSBpbpySltSLKwshIShCCapmUpcpGGL09SbCGyReQW1kRbCLJAURG1DCWEqeJDYjGxtQdVK2BifDnaxBi1cNRCDAAAd17jqHmTqxoAAAAldEVYdGRhdGU6Y3JlYXRlADIwMTYtMDgtMjdUMDM6MDI6MzArMDk6MDBiVITiAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDE2LTA4LTI3VDAzOjAyOjMwKzA5OjAwEwk8XgAAABd0RVh0cG5nOmJpdC1kZXB0aC13cml0dGVuAAinxCzyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 300
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='test_img.png', width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:07.127383Z",
     "start_time": "2019-08-12T11:56:07.017543Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = np.invert(Image.open(\"test_img.png\").convert('L')).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T11:56:07.233241Z",
     "start_time": "2019-08-12T11:56:07.129674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image: 2\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(tf.argmax(output_layer, 1), feed_dict={X: [img]})\n",
    "print (\"Prediction for test image:\", np.squeeze(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thank you<br><br>\n",
    "\n",
    "$\\textbf{Arif Romadhan}$ <br>\n",
    "email : arif.romadhan@bukalapak.com<br>\n",
    "telegram : @SiAnakBatu<br>\n",
    "\n",
    "reference :<br> \n",
    "https://adventuresinmachinelearning.com/python-tensorflow-tutorial/<br>\n",
    "https://pythonprogramminglanguage.com/tensorflow-neural-network/<br>\n",
    "https://www.digitalocean.com/community/tutorials/how-to-build-a-neural-network-to-recognize-handwritten-digits-with-tensorflow<br>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kaggle",
   "language": "python",
   "name": "env_kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
